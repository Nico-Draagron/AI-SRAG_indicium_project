"""
Vector Store - Databricks Vector Search + Embeddings
=====================================================

Gerencia embeddings e busca vetorial usando Databricks Vector Search.

Estrat√©gia:
    - Embeddings: text-embedding-3-small ou similar
    - Vector Store: Databricks Vector Search (nativo)
    - Indexa√ß√£o: Delta Sync para atualiza√ß√£o autom√°tica
    - Retrieval: Top-K com filtros de metadata

Author: AI Engineer Certification - Indicium  
Date: January 2025
Version: 2.0.0
"""

from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from functools import lru_cache
import json
import time
import re

from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_community.vectorstores import DatabricksVectorSearch
from databricks.vector_search.client import VectorSearchClient

# Embeddings providers
try:
    from langchain_openai import OpenAIEmbeddings
    OPENAI_AVAILABLE = True
except:
    OPENAI_AVAILABLE = False

try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    HF_AVAILABLE = True
except:
    HF_AVAILABLE = False


# =============================================================================
# EMBEDDING MANAGER
# =============================================================================

class EmbeddingManager:
    """
    Gerencia cria√ß√£o de embeddings
    
    Providers suportados:
        - OpenAI (text-embedding-3-small) - RECOMENDADO
        - HuggingFace (sentence-transformers)
        - Databricks (futuro)
    
    Dimens√µes:
        - OpenAI small: 1536 dims
        - HF all-MiniLM-L6-v2: 384 dims
    """
    
    @staticmethod
    def get_embeddings(
        provider: str = "openai",
        model: str = "text-embedding-3-small",
        **kwargs
    ) -> Embeddings:
        """
        Factory de embeddings
        
        Args:
            provider: 'openai' ou 'huggingface'
            model: Nome do modelo
            
        Returns:
            Inst√¢ncia de Embeddings
        """
        if provider == "openai":
            if not OPENAI_AVAILABLE:
                raise ImportError("langchain-openai n√£o instalado")
            
            return OpenAIEmbeddings(
                model=model,
                **kwargs
            )
        
        elif provider == "huggingface":
            if not HF_AVAILABLE:
                raise ImportError("sentence-transformers n√£o instalado")
            
            return HuggingFaceEmbeddings(
                model_name=model or "sentence-transformers/all-MiniLM-L6-v2",
                **kwargs
            )
        
        else:
            raise ValueError(f"Provider n√£o suportado: {provider}")
    
    @staticmethod
    def get_embedding_dimensions(provider: str, model: str) -> int:
        """Retorna dimens√µes do embedding"""
        dimensions_map = {
            "text-embedding-3-small": 1536,
            "text-embedding-3-large": 3072,
            "all-MiniLM-L6-v2": 384,
            "all-mpnet-base-v2": 768
        }
        
        return dimensions_map.get(model, 1536)  # Default OpenAI


# =============================================================================
# DATABRICKS VECTOR SEARCH MANAGER
# =============================================================================

@dataclass
class VectorStoreConfig:
    """Configura√ß√£o do Vector Store"""
    catalog: str = "dbx_lab_draagron"
    schema: str = "gold"
    index_name: str = "srag_embeddings_index_v1"  # 6Ô∏è‚É£ Versionamento do √≠ndice
    endpoint_name: str = "srag_vector_endpoint"
    embedding_dimension: int = 1536
    primary_key: str = "doc_id"
    embedding_source_column: str = "content"
    embedding_vector_column: str = "embedding"


class DatabricksVectorStoreManager:
    """
    Gerencia Databricks Vector Search
    
    Workflow:
        1. Criar endpoint (se n√£o existir)
        2. Criar tabela Delta com embeddings
        3. Criar √≠ndice vetorial
        4. Delta Sync autom√°tico
    
    Example:
        >>> manager = DatabricksVectorStoreManager(spark, config)
        >>> manager.create_vector_index(documents)
        >>> results = manager.search("casos de SRAG em SP", k=5)
    """
    
    def __init__(
        self,
        spark,
        config: Optional[VectorStoreConfig] = None,
        embeddings: Optional[Embeddings] = None
    ):
        self.spark = spark
        self.config = config or VectorStoreConfig()
        self.embeddings = embeddings or EmbeddingManager.get_embeddings()
        self.client = VectorSearchClient()
        
        # Nome completo do √≠ndice
        self.full_index_name = f"{self.config.catalog}.{self.config.schema}.{self.config.index_name}"
        
    # =========================================================================
    # SETUP E CRIA√á√ÉO
    # =========================================================================
    
    def create_vector_index(
        self,
        documents: List[Document],
        recreate: bool = False
    ) -> str:
        """
        Cria √≠ndice vetorial completo
        
        Steps:
            1. Criar endpoint (se necess√°rio)
            2. Preparar documentos com embeddings
            3. Salvar em Delta Table
            4. Criar √≠ndice vetorial com Delta Sync
        
        Args:
            documents: Lista de documentos LangChain
            recreate: Se True, deleta √≠ndice existente
            
        Returns:
            Nome do √≠ndice criado
        """
        print(f"üì¶ Criando Vector Index: {self.full_index_name}")
        
        # 1. Criar endpoint
        self._ensure_endpoint_exists()
        
        # 2. Preparar dados com embeddings
        print("üîÑ Gerando embeddings...")
        df_with_embeddings = self._prepare_documents_with_embeddings(documents)
        
        # 3. Salvar em Delta
        print("üíæ Salvando em Delta Table...")
        self._save_to_delta(df_with_embeddings, recreate=recreate)
        
        # 4. Criar √≠ndice vetorial
        print("üîó Criando Vector Index...")
        index = self._create_or_update_index(recreate=recreate)
        
        print(f"‚úÖ Vector Index criado: {self.full_index_name}")
        return self.full_index_name
    
    def create_or_load_index(self, documents: List[Document]) -> bool:
        """
        Garante que o √≠ndice vetorial existe e est√° dispon√≠vel
        
        Args:
            documents: Lista de documentos para criar o √≠ndice se necess√°rio
            
        Returns:
            True se √≠ndice est√° pronto, False caso contr√°rio
        """
        try:
            # Verificar se √≠ndice j√° existe
            existing = self.client.list_indexes(
                endpoint_name=self.config.endpoint_name
            )
            index_names = [idx.get('name', '') for idx in existing.get('indexes', [])]
            
            if self.full_index_name in index_names:
                print(f"‚úÖ √çndice vetorial j√° existe: {self.full_index_name}")
                return True
            else:
                print(f"üîÑ √çndice n√£o encontrado, criando: {self.full_index_name}")
                self.create_vector_index(documents, recreate=False)
                return True
                
        except Exception as e:
            print(f"‚ùå Erro ao verificar/criar √≠ndice: {e}")
            return False
    
    def _ensure_endpoint_exists(self) -> None:
        """Garante que endpoint existe"""
        try:
            endpoints = self.client.list_endpoints()
            endpoint_names = [e['name'] for e in endpoints.get('endpoints', [])]
            
            if self.config.endpoint_name not in endpoint_names:
                print(f"üîß Criando endpoint: {self.config.endpoint_name}")
                self.client.create_endpoint(
                    name=self.config.endpoint_name,
                    endpoint_type="STANDARD"
                )
                print(f"‚úÖ Endpoint criado")
            else:
                print(f"‚úÖ Endpoint j√° existe: {self.config.endpoint_name}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao verificar endpoint: {e}")
    
    def _prepare_documents_with_embeddings(self, documents: List[Document]) -> 'pd.DataFrame':
        """Prepara DataFrame com embeddings para Databricks Vector Search"""
        import pandas as pd
        from datetime import datetime
        
        if not documents:
            raise ValueError("Lista de documentos est√° vazia")
        
        print(f"   üìä Preparando {len(documents)} documentos Gold para embedding...")
        
        # Validar documentos
        valid_documents = []
        for i, doc in enumerate(documents):
            if not doc.page_content or not doc.page_content.strip():
                print(f"   ‚ö†Ô∏è Documento {i} sem conte√∫do - ignorando")
                continue
            if not doc.metadata.get("doc_id"):
                print(f"   ‚ö†Ô∏è Documento {i} sem doc_id - gerando automaticamente")
                doc.metadata["doc_id"] = f"auto_gen_{i}_{int(datetime.now().timestamp())}"
            valid_documents.append(doc)
        
        print(f"   ‚úÖ {len(valid_documents)} documentos v√°lidos para processamento")
        
        # Extrair textos limpos
        texts = [doc.page_content.strip() for doc in valid_documents]
        
        # Gerar embeddings em batch (otimizado)
        print(f"   üîÑ Gerando embeddings usando {self.embeddings.__class__.__name__}...")
        try:
            embeddings_vectors = self.embeddings.embed_documents(texts)
        except Exception as e:
            print(f"   ‚ùå Erro ao gerar embeddings: {e}")
            raise
        
        print(f"   ‚úÖ {len(embeddings_vectors)} embeddings gerados")
        
        # 1Ô∏è‚É£ AJUSTE DE ROBUSTEZ: Validar dimens√£o dos embeddings
        if embeddings_vectors:
            actual_dim = len(embeddings_vectors[0])
            expected_dim = self.config.embedding_dimension
            if actual_dim != expected_dim:
                raise ValueError(
                    f"Dimens√£o do embedding n√£o confere: "
                    f"esperado={expected_dim}, atual={actual_dim}. "
                    f"Verifique a configura√ß√£o do modelo de embedding."
                )
            print(f"   ‚úÖ Dimens√£o validada: {actual_dim}d")
        
        # Construir DataFrame otimizado para Databricks
        data = []
        for doc, embedding in zip(valid_documents, embeddings_vectors):
            # Extrair campos essenciais do metadata
            metadata = doc.metadata.copy()
            
            row = {
                # Campos obrigat√≥rios
                "doc_id": metadata.get("doc_id", ""),
                "content": doc.page_content.strip(),
                "embedding": embedding,
                
                # Campos para filtros
                "source_table": metadata.get("source_table", "unknown"),
                "semantic_type": metadata.get("semantic_type", "general"),
                
                # Campos espec√≠ficos do Gold (se dispon√≠veis)
                "categoria": metadata.get("categoria", None),
                "metrica": metadata.get("metrica", None),
                "uf": metadata.get("uf", None),
                "ano_mes": metadata.get("ano_mes", None),
                "faixa_etaria": metadata.get("faixa_etaria", None),
                
                # Metadata completo como JSON
                "metadata_json": json.dumps(metadata, ensure_ascii=False),
                
                # Timestamp para auditoria
                "created_at": datetime.now().isoformat()
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        
        # Validar DataFrame
        print(f"   üìã Validando DataFrame: {len(df)} linhas, {len(df.columns)} colunas")
        print(f"   üìä Dimens√£o dos embeddings: {len(df.iloc[0]['embedding']) if len(df) > 0 else 'N/A'}")
        
        return df
    
    def _save_to_delta(self, df: 'pd.DataFrame', recreate: bool = False) -> None:
        """Salva DataFrame em Delta Table com otimiza√ß√µes"""
        if df.empty:
            raise ValueError("DataFrame est√° vazio")
        
        table_name = self.full_index_name.replace("_index", "_table")
        print(f"   üíæ Salvando {len(df)} registros em Delta Table: {table_name}")
        
        try:
            # Converter para Spark DataFrame
            spark_df = self.spark.createDataFrame(df)
            
            # Aplicar particionamento por semantic_type para performance
            spark_df = spark_df.repartition("semantic_type")
            
            # Configurar modo de escrita
            mode = "overwrite" if recreate else "append"
            
            # Salvar com otimiza√ß√µes Delta
            writer = spark_df.write.format("delta").mode(mode)
            
            # Configura√ß√µes para melhor performance
            writer = writer.option("delta.autoOptimize.optimizeWrite", "true")
            writer = writer.option("delta.autoOptimize.autoCompact", "true")
            
            # Particionar por semantic_type se recreating
            if recreate:
                writer = writer.partitionBy("semantic_type")
            
            # Executar escrita
            writer.saveAsTable(table_name)
            
            # Otimizar tabela ap√≥s escrita (apenas se recreate)
            if recreate:
                self.spark.sql(f"OPTIMIZE {table_name}")
                print(f"   üîß Tabela otimizada: {table_name}")
            
            # Verificar resultado
            count = self.spark.table(table_name).count()
            print(f"   ‚úÖ Dados salvos: {count} registros totais em {table_name}")
            
        except Exception as e:
            print(f"   ‚ùå Erro ao salvar em Delta: {e}")
            raise
    
    def _create_or_update_index(self, recreate: bool = False) -> Dict:
        """Cria ou atualiza √≠ndice vetorial no Databricks Vector Search"""
        source_table = self.full_index_name.replace("_index", "_table")
        
        try:
            # Verificar se endpoint est√° ativo
            print(f"   üîç Verificando endpoint: {self.config.endpoint_name}")
            endpoint_info = self.client.get_endpoint(self.config.endpoint_name)
            if endpoint_info.get("endpoint_status", {}).get("state") != "ONLINE":
                print(f"   ‚ö†Ô∏è Endpoint n√£o est√° ONLINE: {endpoint_info.get('endpoint_status', {})}")
            
            # Verificar se tabela Delta existe e tem dados
            try:
                table_count = self.spark.table(source_table).count()
                print(f"   üìä Tabela fonte: {source_table} ({table_count} registros)")
                if table_count == 0:
                    raise ValueError(f"Tabela {source_table} est√° vazia")
            except Exception as table_error:
                print(f"   ‚ùå Erro ao verificar tabela: {table_error}")
                raise
            
            # Verificar √≠ndices existentes
            existing = self.client.list_indexes(
                endpoint_name=self.config.endpoint_name
            )
            
            index_names = [idx.get('name', '') for idx in existing.get('indexes', [])]
            
            if self.full_index_name in index_names:
                if recreate:
                    print(f"   üóëÔ∏è Deletando √≠ndice existente: {self.full_index_name}")
                    self.client.delete_index(
                        endpoint_name=self.config.endpoint_name,
                        index_name=self.full_index_name
                    )
                    # Aguardar dele√ß√£o
                    import time
                    time.sleep(10)
                else:
                    print(f"   ‚úÖ √çndice j√° existe: {self.full_index_name}")
                    # Verificar status do √≠ndice
                    index_info = self.client.get_index(
                        endpoint_name=self.config.endpoint_name,
                        index_name=self.full_index_name
                    )
                    print(f"   üìä Status: {index_info.get('status', {}).get('ready', 'unknown')}")
                    return {"status": "exists", "info": index_info}
            
            # Criar novo √≠ndice com configura√ß√µes otimizadas
            print(f"   üîó Criando Vector Index: {self.full_index_name}")
            print(f"   üìã Configura√ß√µes:")
            print(f"      - Tabela fonte: {source_table}")
            print(f"      - Primary key: {self.config.primary_key}")
            print(f"      - Embedding column: {self.config.embedding_vector_column}")
            print(f"      - Dimens√µes: {self.config.embedding_dimension}")
            
            index = self.client.create_delta_sync_index(
                endpoint_name=self.config.endpoint_name,
                index_name=self.full_index_name,
                source_table_name=source_table,
                pipeline_type="TRIGGERED",
                primary_key=self.config.primary_key,
                embedding_dimension=self.config.embedding_dimension,
                embedding_vector_column=self.config.embedding_vector_column
            )
            
            print(f"   ‚úÖ Vector Index criado com Delta Sync")
            print(f"   üîÑ Aguarde a sincroniza√ß√£o inicial...")
            
            # Verificar cria√ß√£o
            try:
                index_status = self.client.get_index(
                    endpoint_name=self.config.endpoint_name,
                    index_name=self.full_index_name
                )
                print(f"   üìä Status inicial: {index_status.get('status', {}).get('ready', 'unknown')}")
            except Exception as status_error:
                print(f"   ‚ö†Ô∏è N√£o foi poss√≠vel verificar status: {status_error}")
            
            return index
            
        except Exception as e:
            print(f"   ‚ùå Erro ao criar √≠ndice vetorial: {str(e)}")
            print(f"   üîß Troubleshooting:")
            print(f"      - Verifique se o endpoint {self.config.endpoint_name} est√° ativo")
            print(f"      - Verifique se a tabela {source_table} existe e tem dados")
            print(f"      - Verifique permiss√µes do Databricks Vector Search")
            raise
    
    # =========================================================================
    # BUSCA E RETRIEVAL
    # =========================================================================
    
    def search(
        self,
        query: str,
        k: int = 5,
        filters: Optional[Dict] = None
    ) -> List[Tuple[Document, float]]:
        """
        Busca sem√¢ntica no Vector Store usando Databricks Vector Search
        
        Args:
            query: Texto da busca
            k: N√∫mero de resultados
            filters: Filtros de metadata (ex: {"semantic_type": "metric"})
            
        Returns:
            Lista de (Document, score) ordenada por relev√¢ncia
            IMPORTANTE: scores maiores = maior similaridade (0.0-1.0+)
        """
        # 3Ô∏è‚É£ AJUSTE: Retry com backoff simples
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # Gerar embedding da query usando cache otimizado
                query_embedding = list(self._get_cached_query_embedding(query))
                
                # 2Ô∏è‚É£ AJUSTE: Sanitizar filtros com whitelist
                filter_conditions = []
                if filters:
                    for key, value in filters.items():
                        safe_value = self._sanitize_filter_value(value)
                        
                        if key == "semantic_type":
                            filter_conditions.append(f"semantic_type = '{safe_value}'")
                        elif key == "source_table":
                            filter_conditions.append(f"source_table = '{safe_value}'")
                        elif key == "ano_mes":
                            filter_conditions.append(f"ano_mes = '{safe_value}'")
                        elif key == "uf":
                            filter_conditions.append(f"uf = '{safe_value}'")
                
                filter_string = " AND ".join(filter_conditions) if filter_conditions else None
                
                # Executar busca vetorial usando m√©todo isolado
                search_results = self._vector_search(query_embedding, k, filter_string)
                
                # Processar resultados
                documents = []
                
                if "result" in search_results:
                    result = search_results["result"]
                    data_array = result.get("data_array", [])
                    scores = result.get("scores", [])
                    
                    for idx, row in enumerate(data_array):
                        try:
                            doc_id = row[0] if len(row) > 0 else f"doc_{idx}"
                            content = row[1] if len(row) > 1 else ""
                            metadata_json = row[2] if len(row) > 2 else "{}"
                            source_table = row[3] if len(row) > 3 else ""
                            semantic_type = row[4] if len(row) > 4 else ""
                            
                            # 4Ô∏è‚É£ Score de similaridade (maior = mais similar)
                            score = scores[idx] if idx < len(scores) else 0.8
                            
                            try:
                                metadata = json.loads(metadata_json) if metadata_json else {}
                            except json.JSONDecodeError:
                                metadata = {}
                            
                            metadata.update({
                                "doc_id": doc_id,
                                "source_table": source_table,
                                "semantic_type": semantic_type
                            })
                            
                            doc = Document(
                                page_content=content,
                                metadata=metadata
                            )
                            
                            documents.append((doc, score))
                            
                        except Exception as row_error:
                            print(f"‚ö†Ô∏è Erro ao processar linha {idx}: {row_error}")
                            continue
                
                # Ordenar por score (maior primeiro = mais similar)
                documents.sort(key=lambda x: x[1], reverse=True)
                
                print(f"‚úÖ Busca conclu√≠da: {len(documents)} documentos encontrados")
                if documents:
                    print(f"   Score mais alto: {documents[0][1]:.4f}")
                
                return documents
                
            except Exception as e:
                if attempt < max_retries - 1:
                    # Backoff simples: 2, 4, 6 segundos
                    backoff_time = 2 * (attempt + 1)
                    print(f"‚ö†Ô∏è Tentativa {attempt + 1} falhou: {str(e)}. Tentando novamente em {backoff_time}s...")
                    time.sleep(backoff_time)
                    continue
                else:
                    # 3Ô∏è‚É£ Log final de erro ap√≥s todas as tentativas
                    print(f"‚ùå Erro na busca vetorial ap√≥s {max_retries} tentativas: {str(e)}")
                    print(f"   Query: '{query[:100]}...'")
                    print(f"   √çndice: {self.full_index_name}")
                    
        # Retornar lista vazia se todas as tentativas falharam
        return []
    
    def search_by_type(
        self,
        query: str,
        semantic_type: str,
        k: int = 5
    ) -> List[Tuple[Document, float]]:
        """
        Busca filtrada por tipo sem√¢ntico
        
        Args:
            query: Texto da busca
            semantic_type: 'metric', 'temporal', 'geographic', 'demographic'
            k: N√∫mero de resultados
        """
        filters = {"semantic_type": semantic_type}
        return self.search(query, k=k, filters=filters)
    
    # =========================================================================
    # MANUTEN√á√ÉO
    # =========================================================================
    
    def sync_index(self) -> None:
        """Sincroniza √≠ndice com Delta Table (Delta Sync)"""
        try:
            self.client.sync_index(
                index_name=self.full_index_name
            )
            print(f"‚úÖ √çndice sincronizado")
        except Exception as e:
            print(f"‚ùå Erro ao sincronizar: {e}")
    
    def delete_index(self) -> None:
        """Deleta √≠ndice vetorial"""
        try:
            self.client.delete_index(
                endpoint_name=self.config.endpoint_name,
                index_name=self.full_index_name
            )
            print(f"‚úÖ √çndice deletado: {self.full_index_name}")
        except Exception as e:
            print(f"‚ùå Erro ao deletar: {e}")
    
    def get_index_stats(self) -> Dict:
        """Retorna estat√≠sticas do √≠ndice"""
        try:
            index = self.client.get_index(
                endpoint_name=self.config.endpoint_name,
                index_name=self.full_index_name
            )
            
            return {
                "index_name": self.full_index_name,
                "status": index.get('status', {}).get('state', 'unknown'),
                "num_rows": index.get('num_rows', 0),
                "dimension": self.config.embedding_dimension
            }
        except Exception as e:
            print(f"‚ùå Erro ao obter stats: {e}")
            return {}
    
    @lru_cache(maxsize=50)
    def _get_cached_query_embedding(self, query: str) -> tuple:
        """8Ô∏è‚É£ Cache otimizado para embeddings de query usando @lru_cache"""
        embedding = self.embeddings.embed_query(query)
        return tuple(embedding)  # tuple para compatibilidade com lru_cache
    
    def _sanitize_filter_value(self, value: str) -> str:
        """2Ô∏è‚É£ Sanitizar valores de filtro usando whitelist (regex)"""
        # Whitelist: apenas alfanum√©ricos, h√≠fens, underscores e espa√ßos
        safe_value = re.sub(r'[^\w\s\-]', '', str(value))
        return safe_value.strip()
    
    def _vector_search(
        self, 
        query_embedding: List[float], 
        k: int, 
        filter_string: Optional[str] = None
    ) -> Dict:
        """M√©todo isolado para execu√ß√£o da busca vetorial"""
        return self.client.similarity_search(
            index_name=self.full_index_name,
            query_vector=query_embedding,
            columns=["doc_id", "content", "metadata_json", "source_table", "semantic_type"],
            num_results=k,
            filters=filter_string
        )


# =============================================================================
# RAG RETRIEVER
# =============================================================================

class SRAGRetriever:
    """
    Retriever customizado para SRAG
    
    Implementa estrat√©gias de busca h√≠bridas:
        - Busca sem√¢ntica
        - Filtros por tipo
        - Reranking por metadata
    """
    
    def __init__(self, vector_store_manager: DatabricksVectorStoreManager):
        self.vsm = vector_store_manager
    
    def retrieve(
        self,
        query: str,
        k: int = 5,
        strategy: str = "semantic"
    ) -> List[Document]:
        """
        Recupera documentos relevantes do Vector Store
        
        Args:
            query: Consulta em linguagem natural
            k: N√∫mero m√°ximo de documentos a retornar
            strategy: 'semantic' | 'hybrid' | 'typed'
        
        Returns:
            Lista de Documents (nunca None, pode ser vazia)
        """
        # 7Ô∏è‚É£ NICE-TO-HAVE: Log m√≠nimo de telemetria
        print(f"üìä Retrieval: strategy={strategy}, k={k}, query_len={len(query)}")
        
        # Valida√ß√£o b√°sica
        if not query or not query.strip() or k <= 0:
            print("‚ö†Ô∏è Query inv√°lida ou k <= 0, retornando lista vazia")
            return []
        
        try:
            if strategy == "semantic":
                documents = self._semantic_retrieve(query, k)
            elif strategy == "hybrid":
                documents = self._hybrid_retrieve(query, k)
            elif strategy == "typed":
                documents = self._typed_retrieve(query, k)
            else:
                print(f"‚ö†Ô∏è Strategy inv√°lida '{strategy}', usando semantic")
                documents = self._semantic_retrieve(query, k)
            
            if not documents:
                print(f"‚ö†Ô∏è Nenhum documento encontrado para query: '{query[:50]}...'")
            else:
                print(f"‚úÖ Retrieval conclu√≠do: {len(documents)} documentos")
            
            return documents
                
        except Exception as e:
            print(f"‚ùå Erro no retrieval: {e}")
            return []
    
    def _semantic_retrieve(self, query: str, k: int) -> List[Document]:
        """
        Busca sem√¢ntica simples por similaridade
        """
        results = self.vsm.search(query, k=k)
        return [doc for doc, score in results]
    
    def _hybrid_retrieve(self, query: str, k: int) -> List[Document]:
        """
        Busca h√≠brida com reranking simples
        Regras: 1) Prioriza gold_resumo_geral, 2) Prioriza dados recentes, 3) Boost por metadata
        """
        # Buscar mais documentos para reranking
        search_k = min(k * 2, 15)
        results = self.vsm.search(query, k=search_k)
        
        if not results:
            return []
        
        query_lower = query.lower()
        
        # Aplicar reranking com regras simples + metadata boost
        ranked_results = []
        for doc, vector_score in results:
            score = vector_score
            
            # Regra 1: Bonus para tabela resumo geral (fonte principal)
            if doc.metadata.get("source_table") == "gold_resumo_geral":
                score *= 1.2
            
            # Regra 2: Bonus para dados de 2024-2025 (mais recentes) 
            ano_mes = doc.metadata.get("ano_mes", "")
            if "2025" in ano_mes or "2024" in ano_mes:
                score *= 1.1
            
            # 5Ô∏è‚É£ MELHORIA: Boost por metadata estruturada (heur√≠stica simples)
            # Boost se UF da query aparece nos metadados
            doc_uf = doc.metadata.get("uf", "").lower()
            if doc_uf and doc_uf in query_lower:
                score *= 1.15  # 15% boost por match geogr√°fico
                
            # Boost se ano/m√™s da query aparece nos metadados  
            if ano_mes and (ano_mes.lower() in query_lower):
                score *= 1.1   # 10% boost por match temporal
            
            ranked_results.append((doc, score))
        
        # Ordenar por score e retornar top-k
        ranked_results.sort(key=lambda x: x[1], reverse=True)
        return [doc for doc, score in ranked_results[:k]]
    
    def _typed_retrieve(self, query: str, k: int) -> List[Document]:
        """
        Busca com detec√ß√£o simples de tipo geogr√°fico/temporal
        """
        query_lower = query.lower()
        semantic_type = None
        
        # Detectar geografia (estados brasileiros)
        if any(uf in query_lower for uf in ["sp", "rj", "mg", "rs", "pr", "sc", "ba", "pe", "ce", "estado", "uf"]):
            semantic_type = "geographic"
        
        # Detectar temporal
        elif any(termo in query_lower for termo in ["m√™s", "ano", "2024", "2025", "tend√™ncia", "janeiro", "dezembro"]):
            semantic_type = "temporal"
        
        # Buscar com ou sem filtro
        if semantic_type:
            results = self.vsm.search_by_type(query, semantic_type, k=k)
        else:
            results = self.vsm.search(query, k=k)
        
        return [doc for doc, score in results]

